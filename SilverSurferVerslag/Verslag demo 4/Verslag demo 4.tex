\documentclass[tt1]{penoverslag}

%%% PACKAGES
\usepackage{lipsum}
\usepackage{gensymb}
\usepackage [dutch] {babel}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{listings}
\usepackage{subcaption}
\usepackage{lscape}


\begin{document}

\team{Zilver} % teamkleur
\members{Sam Gielis\\
         Sophie Marien\\
         Toon Nolten\\
         Nele Rober\\
         Gerlinde Van Roey\\
         Maxim Van Mechelen} % teamleden

\maketitlepage

\begin{abstract}
Het P\&O-project heeft als doel vier autonome robots \textit{Team Treasure Trek} te laten spelen. De robots moeten hierbij in een onbekende doolhof op zoek naar een bepaald voorwerp. Voor elke robot wordt een ander voorwerp gereserveerd. Wanneer een robot zijn voorwerp gevonden heeft, komt hij te weten met welke robot hij moet samenwerken. Elk duo moet de twee voorwerpen bij elkaar brengen. Wie hier eerst in slaagt, wint. Dit verslag beschrijft de invulling die team Zilver aan het project gaf.\\

De robot is voorzien van een lichtsensor, een infraroodsensor en een ultrasone sensor. De laatste twee staan vast gemonteerd en kunnen niet onafhankelijk van de robot bewegen. De lichtsensor kan wegklappen opdat de robot over een wip kan rijden. Verder is de robot voorzien van een soort schep met klittenband waarmee hij het voorwerp, ook voorzien van klittenband, kan oprapen. Dit gebeurt door het voorwerp te klemmen tussen de muur en de robot zodat het in de schep valt. Met behulp van de klittenband zit het goed vast.\\

De robot kan een doolhof verkennen en er een map van bijhouden. Wanneer een tegel gevonden wordt die mogelijk een voorwerp bevat, zal deze eerst nagekeken worden alvorens verder het doolhof te verkennen. Via RabbitMQ kunnen de robots en simulators met elkaar communiceren. Zo kunnen de duo's een plaats afspreken om elkaar te ontmoeten.\\

Een computerprogramma simuleert de werking van robots. Deze simulator kan vier robots tegelijk simuleren of kan in hybride vorm gebruikt worden (waarbij \'e\'en fysieke en drie virtuele robots gebruikt worden). De gesimuleerde robots gedragen zich volledig analoog aan de fysieke robot.
\end{abstract}

%figuur robot
\begin{figure}[!hb]
\begin{flushright}
    \includegraphics[width=0.8\textwidth]{robotFP}
    \label{fig:robotFP2}
\end{flushright}
\end{figure}

\newpage
\setcounter{tocdepth}{2}
\tableofcontents

\newpage


% == INLEIDING == %
\section{Inleiding} % 4 ok
\label{ssec:inl}
In het kader van het vak `Probleemoplossen en Ontwerpen: computerwetenschappen' wordt gewerkt rond autonome intelligente robots. Verschillende teams bouwen en programmeren een robot met behulp van LEGO Mindstorms \cite{mindstorms}. Deze robot moet uiteindelijk samen met drie andere robots volledig autonoom \textit{Team Treasure Trek} kunnen spelen.\\

De eerste demonstratie bestaat erin de robot te laten rondrijden in een doolhof. De robot is in staat zijn voorwerp te zoeken en op te pikken terwijl de drie overige robots gesimuleerd worden. Bij het oppikken moet de robot dit laten weten aan zijn teamgenoot. Het is ook mogelijk met vier virtuele robots te werken. De virtuele robots communiceren met elkaar via RabbitMQ.\\


\section{Bouw robot}
\label{ssec:bouwrob}
LEGO Mindstorms \cite{mindstorms} biedt een bouwpakket voor een robot aan. Een NXT-microcomputer laat toe de robot te programmeren. Met behulp van leJOS \cite{leJOS} kan dit in Java.


\subsection{Fysieke bouw}
\label{ssec:fysb}

De fysieke bouw van de robot is grotendeels gebaseerd op die van het eerste semester. Enkele aanpassingen waren echter nodig om de robot geschikt te maken voor de nieuwe opdracht. De robot moet in staat zijn een voorwerp, met name een wc-rolletje, op te nemen. Verder bevat de opdracht enkele aspecten die extra sensoren impliceren: het detecteren van andere robots, het detecteren van de wip, vaststellen of het voorwerp daadwerkelijk is opgepakt,...\\
 
Op vlak van sensoren zijn twee aspecten verandert ten opzichte van het eerste semester. De druksensoren aan weerszijde van de lichtsensor zijn weggehaald. Deze hadden als doel te detecteren wanneer er tegen een muur werd gebotst tijdens het witte-lijnalgoritme. Ze zijn echter nooit ge\"implementeerd en bleken ook niet nodig te zijn.

Een infraroodsensor werd gemonteerd bovenop de robot. Deze infraroodsensor kan infraroodlicht detecteren. Er is een bal beschikbaar die dit infraroodlicht uitzendt. Wanneer deze bal onder een wip geplaatst wordt\footnote{De Scheidsrechtercommissie heeft nog niet besloten of de al hiervoor gebruikt zal worden.}, kan de robot makkelijk detecteren of de wip omhoog staat (en dus niet toegankelijk is) of omlaag. In dat tweede geval blokkeert de wip immers al het licht en detecteert de sensor niets.\\

Verschillende opstellingen zijn mogelijk om het voorwerp mee te nemen. Er moet rekening gehouden worden met de beperking van bewegingsvrijheid die het voorwerp teweeg kan brengen. Het is mogelijk het voorwerp over de grond te laten slepen, maar dit zorgt voor extra wrijving en verhoogt de kans dat het voorwerp losgeraakt. Bovendien moet de robot een wip kunnen passeren, ook wanneer hij het voorwerp bij zich heeft. 
 
Aanvankelijk werd gekozen een schep achteraan de robot te monteren, gebruik makend van een extra motor om het voorwerp `op te scheppen' (zie figuur \ref{fig:robotBouw}). Dit geeft als voordeel dat de wip zonder probleem te gepasseerd kan worden en dat het voorwerp stevig vast zit. De robot krijgt dan echter een te grote lengte waardoor hij onmogelijk kan omkeren zonder tegen een muur aan te botsen. Deze opstelling kon daarom niet behouden worden.

De robot heeft een schep vooraan. De schep is opgebouwd uit een deel van een wc-rol. Dit is immers de ideale vorm om het voorwerp, het wc-rolletje, op te nemen. De schep is, net zoals het voorwerp, voorzien van een strook klittenband (nog niet op de foto). Dit biedt extra zekerheid dat het voorwerp niet verloren geraakt. Figuur \ref{fig:robotBouw} toont een gedetailleerd zicht op de schep en het voorwerp.\\

Net zoals vorig semester zijn de ultrasone- en de infraroodsensor vast gemonteerd op de robot. De lichtsensor~-~en de schep die hieraan vast hangt~-~kunnen echter bewegen ten opzichte van de robot. Dit gebeurt met behulp van een scharnier, er werd geen extra motor gebruikt. Dit is nodig om over een wip te kunnen rijden. Het scharnier zorgt ervoor dat de lichtsensor wegklapt bij contact met de wip en later door de zwaartekracht weer terug op zijn plaats klapt. Zo zit de lichtsensor niet in de weg.

% figuren robot, oud en nieuw
\begin{figure}
\centering
	\begin{subfigure}[hb]{0.48\textwidth}
	\centering
		\includegraphics[width=\textwidth]{robotSchepOud}
		\caption{schep achteraan}
	\end{subfigure}%
	\begin{subfigure}[h]{0.5\textwidth}
		\centering
		\includegraphics[width=\textwidth]{robotSchepNieuw}
	\caption{schep vooraan}
\end{subfigure}
\caption{Bouw van de robot.}
\label{fig:robotBouw}
\end{figure}

% figuren detail schep
\begin{figure}
\centering
	\begin{subfigure}[h]{0.5\textwidth}
	\centering
		\includegraphics[width=\textwidth]{schepZonder}
	\end{subfigure}%
	\begin{subfigure}[hb]{0.5\textwidth}
		\centering
		\includegraphics[width=\textwidth]{schepMet}
\end{subfigure}
\caption{Detail van de schep, met en zonder voorwerp.}
\label{fig:robotSchep}
\end{figure}


% == ALGORITMES == %
\section{Algoritmes}
Voor volgende algoritmes wordt verwezen naar het verslag van het eerste semester. Deze algoritmes worden dit semester zonder aanpassingen opnieuw gebruikt.
\begin{itemize}
	\item Rechtzetten op een witte lijn
	\item Centreren aan de hand van twee muren
	\item Lezen van een barcode
	\item Vinden van het kortste pad
\end{itemize}

Nieuwe en aangepaste algoritmes worden verder beschreven.

% == zoeken van het voorwerp == %
\subsection{Zoeken van het voorwerp} %
\label{ssec:algoZoek}
Om het voorwerp te vinden moet de robot aanvankelijk het doolhof verkennen. De robot gebruikt hiervoor een verken-algoritme. Elke tegel die de robot passeert, wordt gemarkeerd. Indien alle tegels gemarkeerd zijn, is de volledige doolhof doorzocht. Elke tegel houdt een boolean bij die deze markering voorstelt.

Bij elke tegel onthoudt de robot alle uitwegen (de naburige tegels). Vervolgens slaat hij de laatste nog niet bekeken uitweg in. Wanneer de robot op een doodlopend stuk komt, keert hij terug tot een kruispunt waar nog niet alle uitwegen van bekeken werden. De robot gebruikt het kortste-pad-algoritme om de weg naar dit kruispunt te bepalen.\\

Enkele optimalisaties werden doorgevoerd in het verken-algoritme. De genoemde aanpassing implementeert steeds ook de aanpassingen die eerder werden toegevoegd. Tabel~\ref{tab:resultVerken} geeft de resultaten van de aanpassingen weer. Figuur~\ref{fig:resultVerkenE} toont de gebruikte doolhoven en de uitvoering van het algoritme met aanpassing E. Er werd getracht het aantal draaiingen en afgelegde afstand te minimaliseren.

\begin{description}
\item[A] basisalgoritme zonder optimalisatie: draai bij elke tegel vier keer (eindig in startori\"entatie) en neem de laatste tile in de queue als volgende tile.
\item[B] neem steeds de buur die met het minst aantal rotaties bereikt kan worden als volgende tile.
\item[C] draai bij elke tegel slechts drie keer (eindig niet meer in startori"entatie).
\item[D] muren die vanuit een naburige tile reeds gedetecteerd werden, worden niet nog eens nagekeken.
\item[E] tiles waarvan de vier zijden al gekend zijn en geen `straight' zijn, worden niet meer bezocht (enkel `straights' kunnen barcodes bevatten, dus dit is geen probleem)
\end{description}

%resultaten lichtsensor
\begin{table}[!hb]
\begin{center}
    \begin{tabular}{ c ||  c | c | c | c }
     & \multicolumn{2}{|c|}{map 1}& \multicolumn{2}{|c}{map 2} \\
    optimalisatie & gedraaid & cm afgelegd & gedraaid & cm afgelegd\\ \hline \hline
    A & 14400 & 2160 & 10620 & 1080 \\ \hline
    B & 13770 & 1920 & 10800 & 1160 \\ \hline
    C & 11970 & 2000 & 9090 & 1080 \\ \hline
    D & 9180 & 2000 & 6570 & 1080\\ \hline
    E & 8820 & 1880 & 6570 & 1080\\
    \end{tabular}
    \caption{Verbeteringen aan het verkenalgoritme}
    \label{tab:resultVerken}
\end{center}
\end{table}

% figuren verkenning doolhof
\begin{figure}
\centering
	\begin{subfigure}[hb]{0.64\textwidth}
	\centering
		\includegraphics[width=\textwidth]{verkenMap1E}
		\caption{map 1}
	\end{subfigure}%
	\begin{subfigure}[hb]{0.36\textwidth}
		\centering
		\includegraphics[width=\textwidth]{verkenMap2E}
	\caption{map 2}
\end{subfigure}
\caption[Verkennen van een doolhof]{Verkennen van een doolhof met implementatie van aanpassing E. Deze aanpassing maakt dat in map 1 niet alle tegels bezocht hoeven te worden. In map 2 doet deze situatie zich niet voor. Dit is te wijten aan de opbouw van de doolhof.}
\label{fig:resultVerkenE}
\end{figure}

Een extra optimalisatie geeft prioriteit aan het vinden van het voorwerp. Een voorwerp kan zich enkel bevinden op een `dead-end', voorafgegaan door een `straight' die een barcode bevat. Deze barcode identificeert het voorwerp. Wanneer een mogelijke voorwerp-locatie gevonden wordt, wordt zo snel mogelijk nagegaan of het om het juiste voorwerp gaat. In sommige gevallen is het niet mogelijk rechtstreeks naar de locatie te gaan omdat het doolhof daar nog niet verkend is. In dat geval wordt verder verkend in de richting van de locatie. De `dead-end' zelf hoeft niet bezocht te worden wanneer uit de barcode blijkt dat het niet om het juiste voorwerp gaat, zodat optimalisatie E nog steeds geldt.\\

Nadat het voorwerp gevonden is, probeert de robot zijn teamgenoot te contacteren. Indien de teamgenoot zijn voorwerp nog niet heeft of wanneer de mappen van beide robots nog niet combineerbaar zijn, gaat de robot verder met het verkennen van het doolhof. Hierbij wordt nog steeds prioriteit gegeven aan voorwerp-locaties. Deze bevatten immers unieke barcodes die het later makkelijker maken de mappen te combineren.

Als alternatief kan de robot zich naar het voorwerp van de teamgenoot begeven om daar op hem te wachten (niet te dicht bij om niet in de weg te staan). Deze extra optie wordt voorlopig nog niet ge\"implementeerd omdat nog niet duidelijk is in welke gevallen de strategie het best werkt.

% nog niet voor deze demo!
%\subsection*{Algoritme om zo snel mogelijk naar de andere robot te gaan}
%Hierbij dachten we aan het kortste-pad-algoritme. Dit zal wel nog aangepast moeten worden aan zowel draaien als vooruit rijden (draaien was nog niet in rekening gebracht).\\ Er moet ook nog rekening gehouden worden als de andere robot zou wegrijden. De robot mag hierdoor niet in een loop terechtkomen. Er zou moeten gecommuniceerd worden wie naar wie toerijdt, of dat er naar een gezamenlijke tegel moet gereden worden. \\
%Als de andere robot zou wegrijden zou er een afstand kunnen bijgehouden worden die dan opnieuw berekent wordt als de afstand niet kleiner wordt.

% == SOFTWARE == %
\section{Software}
\label{secc:softw}
De software bestaat uit twee delen: een project dat op de NXT van de robot loopt (sectie \ref{ssec:robot}) en een project dat op de computer loopt (sectie \ref{ssec:Sdesign}). Alles wordt aangestuurd via de \textit{Graphical User Interface (GUI)} (sectie \ref{ssec:GUI}). Deze laat toe de robot te besturen en de reacties van de robot weer te geven. Via de GUI kan ook een virtuele robot aangestuurd worden: de simulator (sectie \ref{ssec:simulator}).\\

\subsection{Software design}
\label{secc:Sdesign}
Een overzicht van het ontwerp wordt weergegeven in het klassendiagramma van figuur \ref{fig:klasdia}.\\

De Main-methode bevindt zicht in de GUI-klasse. Deze maakt een \textit{SimulatorPanel}-object aan. Dit is een overkoepelend panel waarin meerdere \textit{Viewports} zitten. Een \textit{OverallViewport} geeft de volledige doolhof en alle robots erin weer. Dit kan uiteraard enkel wanneer een gekende virtuele doolhof gebruikt wordt. Een \textit{SimulatorViewport} geeft de wereld van \'e\'en robot (eventueel gesimuleerd) weer: de sensorwaarden en de muren die hij reeds ontdekt heeft. Dit kan echter alleen wanneer deze robot zijn informatie doorgeeft aan de \textit{Viewport}. Een wereld waarvan niets geweten is, kan niet worden weergegeven. Dit is het geval voor robots van andere teams (behalve van de teamgenoot, deze stuurt zijn hele map door). Het aantal \textit{SimulatorViewports} hangt daarom af van het aantal gekende werelden. Deze verdeling wordt weergegeven in tabel \ref{tab:aantViewports}.\\

\begin{table}[h]
\begin{center}
    \begin{tabular}{ c | c | c || c | c}
    wij & wij & anderen & aantal & aantal \\
    fysiek & gesimuleerd & fysiek/gesimuleerd & OveralViewports & SimulatorViewports\\ \hline \hline
    1 & 3 & 0 & 1 & 4\\
    0 & 4 & 0 & 1 & 4\\
    1 & 0 & 3 & 0 & 2\\
    0 & 1 & 3 & 0 & 2\\
    \end{tabular}
    \caption{Overzicht aantal OveralViewports en aantal SimulatorViewports}
    \label{tab:aantViewPorts}
\end{center}
\end{table}

In het geval waarbij twee \textit{SimulatorViewports} worden gebruikt, zal \'e\'en van beide aanvankelijk leeg zijn. Deze \textit{Viewport} geeft de wereld van de teamgenoot weer. Wie deze teamgenoot is, wordt echter pas bekend wanneer beide leden van het team hun voorwerp gevonden hebben.\\
\begin{landscape}

% figuren klassendiagramma
\begin{figure}
\centering
	\begin{subfigure}[h]{0.52\textwidth}
	\centering
		\includegraphics[width=\textwidth]{KlasGUI}
		\caption{map 1}
	\end{subfigure}%
	\begin{subfigure}[h]{0.52\textwidth}
		\centering
		\includegraphics[width=\textwidth]{KlasPilot}
	\caption{map 2}
\end{subfigure}%
\begin{subfigure}[h]{0.52\textwidth}
		\centering
		\includegraphics[width=\textwidth]{KlasRobot}
	\caption{map 2}
\end{subfigure}
\caption{Klassendiagramma}
\label{fig:klasDia}
\end{figure}
\end{landscape}

Elke \textit{Viewport} maakt een eigen \textit{Pilot} aan. Er zijn verschillende soorten \textit{Pilots} die elk een implementatie van \textit{PilorInterface} zijn. De keuze van \textit{Pilot} hangt af van het type robot. Een robot waarvan de wereld niet kan worden voorgesteld, heeft een \textit{DummyPilot}. Deze bevat enkel get-methodes, want deze robot kan niet worden aangestuurd. Een robot die gesimuleerd wordt, heeft een \textit{SimulatorPilot}. Deze berekent zelf zijn sensorwaarden op basis van een virtuele doolhof. Een fysieke robot krijgt een \textit{RobotPilot} die via de \textit{Communicator} in verbinding staat met de fysieke robot. Deze krijgt zijn sensorwaarden terug van de robot via de \textit{InfoReceiversThread} en de \textit{StatusInfoBuffer}. Deze \textit{Pilots} zijn de `hersenen' van deze robots/simulators. De \textit{Viewports} geven enkel weer wat de robots uitvoeren, zij berekenen en beslissen niets.

\subsection{RabbitMQ}
\label{secc:RabbMQ}
Via RabbitMG wordt de communicatie met de andere robots verzorgt. RabbitMQ werkt via queue's. %.. en nog verdere info

\subsection{GUI}


\subsection{Simulator}
\begin{itemize}
\item Beschrijving van de simulator.
\end{itemize}



\subsection{\ldots}
\ldots


% == BESLUIT == %
\section{Besluit}
De uiteindelijke bouw van de robot bestaat uit een infrarood sensor vanboven op de ultrasone sensor en een schepsysteem voor het voorwerp vooraan de robot. Op het schepsysteem is velcro aangebracht zodat het voorwerp stevig vastzit. De lichtsensor heeft een scharnier gekregen, zodat als de robot over een wip rijdt, de lichtsensor niet in de weg steekt. 





\newpage
\bibliographystyle{siam}
\bibliography{biblio.bib}

\begin{thebibliography}{9}
\bibitem{mindstorms}
\textit{Lego Mindstorms}:  Een uitbreiding op de LEGO bouwstenen waarmee kleine, aanpasbare en programmeerbare robots gebouwd kunnen worden. Een centrale besturingsmodule (`the brick') kan geprogrammeerd worden met verschillende programmeertalen. In eerdere versies werd een RCX gebruikt voor de brick, nu wordt met NXT gewerkt. De brick kan enkele motoren aandrijven. Bovendien kunnen er verschillende sensoren, o.a. een ultrasone sensor en een lichtsensor, aangesloten worden.  \mbox{[www.lego.com]} \mbox{[http://en.wikipedia.org/wiki/Lego\textendash Mindstorms]}

\bibitem{leJOS}
\textit{leJOS}: Een kleine Java Virtuele Machine die toelaat de NXT-brick te programmeren. leJOS voorziet verschillende klassen die o.a. de motoren aansturen en een bluetoothverbinding opzetten.  \mbox{[http://lejos.sourceforge.net/]}

\bibitem{A*}
\textit{A*}: Een optimaal zoekalgoritme. \textit{A*} kiest zijn volgende punt op basis van een kostenfunctie: de werkelijke kost om tot de beschouwde buur te geraken, plus de geschatte kost om van dat punt naar het doel te geraken. Met andere woorden, het algoritme combineert een heuristisch algoritme met een kostenalgoritme. Zie ook de cursus \textit{Artifici\"ele Intelligentie (H06U1A)} door Daniel De Schreye.

\bibitem{manhattan}
\textit{Manhattanafstand:} Deze heuristiek tekent vanuit het ene punt een horizontale lijn en vanuit het andere punt een verticale lijn. De gemeten afstand is die van het ene punt tot het snijpunt, plus die van het andere punt tot het snijpunt.\\
In de doolhof wordt geen rekening gehouden met muren.\\
De Manhattanafstand verwijst naar een gelijknamige stadsdeel in New~York~City~VSA). New~York werd in het jaar~1625 door de Nederlanders gesticht. De straten werden in dambordpatroon gelegd: `Avenues' van noord naar zuid en `Streets' van oost naar west.\\
\mbox{$[http://nl.wikipedia.org/wiki/Manhattan\_(New\_York)]$}\\ \mbox{$[http://nl.wikipedia.org/wiki/New\_York\_City]$}

\end{thebibliography}


\end{document}
